# Group project: Real or Not? NLP with Disaster Tweets
## Master Information Systems: Data Mining and Machine Learning 2020
### Group Nestle

Team members: Agon Husejni, Alberto Molinaro, Mila Saqipi

### üïµÔ∏è Project description

Real or Not? NLP with Disaster Tweets: In this project, we build a Machine Learning model that can predict which tweets are about a real disaster and which are not. The project topic is based around a Kaggle competition. Have you ever wondered if the news were true or not? It is what we are trying to do with our prediction model on tweet related to disasters. Given a set of tweets, we are trying to predict if the messages in the tweets are true or not. We will try to build a model with the best possible accuracy with the data provided.

### üóÑ Data

In the data file, you can find the training data which we use for training our model and the test data which we use to calculate the accuracy of our model. The sample data submission is the format in which we can submit a model on AIcrowd. You can also find the clean data that we created and exported from the notebook.

### üë©‚Äçüíª Code

In the code file, you can find the code that gave us the best accuracy on the test data. We got an accuracy of 0.823. This means that in 82.3% of the cases, our model is right on the predictions. You can try to run our notebook to obtain the csv file with the predictions. In comparison with the base rate that is 0.57, it is a good model.

### üñã Summary of the weeks

In these files, you can find and follow the progress of our work through the weeks in the summary slides and see what we did to improve our model.

### üíª Our results 

#### Week 1:
 - First submission without any data cleaning: accuracy of the model = 0.79
 - This will be our baseline to build the model

#### Week 2:
 - Several submissions, the best one: accuracy of the model = 0.817
 - Modifications: Cross-validation in classifier and data cleaning

#### Week 3:
 - Several submissions, the best one: accuracy of the model = 0.819
 - Modifications: Test of several different classifier and parameters
 
#### Week 4:
 - Two improvements: accuracy goes from 0.19 to 0.82 and another improvement, best accuracy = 0.823
 - Modifications: advanced data cleaning, searching the best hyperparameters with GridSearch with different classifiers

### üìπ Link to the video
Soon!
