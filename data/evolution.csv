Date,accuracy_score,jobs_done,model,parameters,Vectorizer or tokenizer
11.15.20,0.793,"Only text - Raw submission - no cleaning, simple model (LogisticRegressionCV)",LogisticRegressionCV,default,TF-IDF - default
11.16.20,0.793,Only text - Still simple model but overcleaned,LogisticRegressionCV,default,TF-IDF - default
11.17.20,0.793,,,,
11.18.20,0.793,,,,
11.19.20,0.793,,,,TF-IDF - default
11.20.20,0.817,Merged keywords and text together + Tried some minor parameters for LogisticRegressionCV + reduced the cleaning ,LogisticRegressionCV,"(cv=5, max_iter=10000)",
11.21.20,0.817,,,,
11.22.20,0.817,,,,
11.23.20,0.817,,,,
11.24.20,0.817,,,,
11.25.20,0.817,,,,
11.26.20,0.819,Similar LogisticRegressionCV + TF-IDF tweaking,LogisticRegressionCV,"(Cs=20, cv=5, max_iter=10000)",TF-IDF - default
11.27.20,0.815,"Same + merged location + tried other models (K-NN, RandomForest)",LogisticRegressionCV,"(Cs=20, cv=5, max_iter=10000)",TF-IDF - default
11.28.20,0.817,Same model but tried BOW,LogisticRegressionCV,"(Cs=20, cv=5, max_iter=10000)",BOW & CountVectorizer - default
11.29.20,0.817,,,,
11.30.20,0.817,,,,
12.01.20,0.817,,,,
12.02.20,0.817,,,,
12.03.20,0.817,,,,
12.04.20,0.817,,,,
12.05.20,0.817,Started all over - integrated GridSearchCV but kept the same cleaning,LogisticRegression,"(C=1, max_iter=10000)",TF-IDF - default
12.06.20,0.806,GridSearchCV + a lot of cleaning + PCA,LogisticRegression,"(C=2, max_iter=10000)",TF-IDF - default
12.07.20,0.818,RandomizedSearchCV,LogisticRegression,"(C=3, max_iter=10000)",TF-IDF - default
12.08.20,0.82,Better GridSearchCV ,LogisticRegression,"(C=1.0, max_iter=10000, multi_class='ovr')",TF-IDF - default
12.09.20,0.823,Same GridSearchCV + fixing some spelling mistakes + tweaking tf-idf parameters,LogisticRegression,"(C=2.2357, max_iter=10000)","(min_depth=0.01, max_depth=0.9, n_gram_range=(1,3)"
12.10.20,0.835,Even better GridSearchCV + optimiting TF-IDF parameters (through mega GridSearchCV),LogisticRegression,"(C=1.623776739188721, class_weight=None, dual=False, fit_intercept=True, intercept_scaling=1, l1_ratio=None, max_iter=10000, multi_class='auto', n_jobs=2, penalty='l2', random_state=777, solver='lbfgs', tol=0.01, verbose=0, warm_start=False)","(tokenizer=spacy_tokenizer, encoding='latin-1', min_df=0.0001, max_df=0.975, ngram_range=(1, 2),  analyzer='word', sublinear_tf=True)"
