Date,accuracy_score,jobs_done,model,parameters,Vectorizer or tokenizer
15.11.29,0.793,"Only text - Raw submission - no cleaning, simple model (LogisticRegressionCV)",LogisticRegressionCV,default,TF-IDF - default
16.11.29,0.793,Only text - Still simple model but overcleaned,LogisticRegressionCV,default,TF-IDF - default
17.11.29,,,,,
18.11.29,,,,,
19.11.29,,,,,TF-IDF - default
20.11.29,0.817,Merged keywords and text together + Tried some minor parameters for LogisticRegressionCV + reduced the cleaning ,LogisticRegressionCV,"(cv=5, max_iter=10000)",
21.11.29,,,,,
22.11.29,,,,,
23.11.29,,,,,
24.11.29,,,,,
25.11.29,,,,,
26.11.29,0.819,Similar LogisticRegressionCV + TF-IDF tweaking,LogisticRegressionCV,"(Cs=20, cv=5, max_iter=10000)",TF-IDF - default
27.11.29,0.815,"Same + merged location + tried other models (K-NN, RandomForest)",LogisticRegressionCV,"(Cs=20, cv=5, max_iter=10000)",TF-IDF - default
28.11.29,0.817,Same model but tried BOW,LogisticRegressionCV,"(Cs=20, cv=5, max_iter=10000)",BOW & CountVectorizer - default
29.11.29,,,,,
30.11.29,,,,,
01.12.29,,,,,
02.12.29,,,,,
03.12.29,,,,,
04.12.29,,,,,
05.12.29,0.817,Started all over - integrated GridSearchCV but kept the same cleaning,LogisticRegression,"(C=1, max_iter=10000)",TF-IDF - default
06.12.29,0.806,GridSearchCV + a lot of cleaning + PCA,LogisticRegression,"(C=2, max_iter=10000)",TF-IDF - default
07.12.29,0.818,RandomizedSearchCV,LogisticRegression,"(C=3, max_iter=10000)",TF-IDF - default
08.12.29,0.82,Better GridSearchCV ,LogisticRegression,"(C=1.0, max_iter=10000, multi_class='ovr')",TF-IDF - default
09.12.29,0.823,Same GridSearchCV + fixing some spelling mistakes + tweaking tf-idf parameters,LogisticRegression,"(C=2.2357, max_iter=10000)","(min_depth=0.01, max_depth=0.9, n_gram_range=(1,3)"
10.12.29,,Even better GridSearchCV + optimiting TF-IDF parameters (through mega GridSearchCV),LogisticRegression,"(C=1.623776739188721, class_weight=None, dual=False, fit_intercept=True, intercept_scaling=1, l1_ratio=None, max_iter=10000, multi_class='auto', n_jobs=2, penalty='l2', random_state=777, solver='lbfgs', tol=0.01, verbose=0, warm_start=False)","(tokenizer=spacy_tokenizer, encoding='latin-1', min_df=0.0001, max_df=0.975, ngram_range=(1, 2),  analyzer='word', sublinear_tf=True)"
,,,,,
,,,,,
,,,,,
,,,,,